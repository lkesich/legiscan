{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42908a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parsons import Table, Redshift\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import zipfile\n",
    "import io\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "\n",
    "rs = Redshift()\n",
    "table = Table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d579c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### pylegiscan functions adapted from https://github.com/poliquin/pylegiscan/blob/master/pylegiscan/legiscan.py\n",
    "\n",
    "class LegiScanError(Exception):\n",
    "    pass\n",
    "\n",
    "class LegiScan(object):\n",
    "    BASE_URL = 'http://api.legiscan.com/?key={0}&op={1}&{2}'\n",
    "\n",
    "    def __init__(self, apikey=None):\n",
    "        \"\"\"LegiScan API.  State parameters should always be passed as\n",
    "           USPS abbreviations.  Bill numbers and abbreviations are case\n",
    "           insensitive.  Register for API at http://legiscan.com/legiscan\n",
    "        \"\"\"\n",
    "        # see if API key available as environment variable\n",
    "        if apikey is None:\n",
    "            apikey = os.getenv('LEGISCAN_API_KEY')\n",
    "        self.key = apikey.strip()\n",
    "\n",
    "    def _url(self, operation, params=None):\n",
    "        \"\"\"Build a URL for querying the API.\"\"\"\n",
    "        if not isinstance(params, str) and params is not None:\n",
    "            params = urlencode(params)\n",
    "        elif params is None:\n",
    "            params = ''\n",
    "        return self.BASE_URL.format(self.key, operation, params)\n",
    "\n",
    "    def _get(self, url):\n",
    "        \"\"\"Get and parse JSON from API for a url.\"\"\"\n",
    "        req = requests.get(url)\n",
    "        if not req.ok:\n",
    "            raise LegiScanError('Request returned {0}: {1}'\\\n",
    "                    .format(req.status_code, url))\n",
    "        data = json.loads(req.content)\n",
    "        if data['status'] == \"ERROR\":\n",
    "            raise LegiScanError(data['alert']['message'])\n",
    "        return data\n",
    "\n",
    "    def get_session_list(self, state):\n",
    "        \"\"\"Get list of available sessions for a state.\"\"\"\n",
    "        url = self._url('getSessionList', {'state': state})\n",
    "        data = self._get(url)\n",
    "        return data['sessions']\n",
    "\n",
    "    def get_dataset_list(self, state=None, year=None):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getDatasetList', {'state': state})\n",
    "        elif year is not None:\n",
    "            url = self._url('getDatasetList', {'year': year})\n",
    "        else:\n",
    "            url = self._url('getDatasetList')\n",
    "        data = self._get(url)\n",
    "        return data['datasetlist']\n",
    "\n",
    "    def get_dataset(self, id, access_key):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        url = self._url('getDataset', {'id': id, 'access_key': access_key})\n",
    "        data = self._get(url)\n",
    "        return data['dataset']\n",
    "    \n",
    "    def get_session_people(self, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier.\n",
    "        \"\"\"\n",
    "        if session_id is not None:\n",
    "            url = self._url('getSessionPeople', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier.')\n",
    "        data = self._get(url)\n",
    "        return data['sessionpeople']\n",
    "      \n",
    "    def get_master_list(self, state=None, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getMasterList', {'state': state})\n",
    "        elif session_id is not None:\n",
    "            url = self._url('getMasterList', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier or state.')\n",
    "        data = self._get(url)\n",
    "        return [data['masterlist'][i] for i in data['masterlist']]\n",
    "    \n",
    "    def get_master_list_raw(self, state=None, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier, optimized for change hash detection.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getMasterListRaw', {'state': state})\n",
    "        elif session_id is not None:\n",
    "            url = self._url('getMasterListRaw', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier or state.')\n",
    "        data = self._get(url)\n",
    "        return [data['masterlist'][i] for i in data['masterlist']]\n",
    "\n",
    "    def get_bill(self, bill_id=None, state=None, bill_number=None):\n",
    "        \"\"\"Get primary bill detail information including sponsors, committee\n",
    "           references, full history, bill text, and roll call information.\n",
    "\n",
    "           This function expects either a bill identifier or a state and bill\n",
    "           number combination.  The bill identifier is preferred, and required\n",
    "           for fetching bills from prior sessions.\n",
    "        \"\"\"\n",
    "        if bill_id is not None:\n",
    "            url = self._url('getBill', {'id': bill_id})\n",
    "        elif state is not None and bill_number is not None:\n",
    "            url = self._url('getBill', {'state': state, 'bill': bill_number})\n",
    "        else:\n",
    "            raise ValueError('Must specify bill_id or state and bill_number.')\n",
    "        return self._get(url)['bill']\n",
    "\n",
    "    def get_roll_call(self, roll_call_id):\n",
    "        \"\"\"Roll call detail for individual votes and summary information.\"\"\"\n",
    "        data = self._get(self._url('getRollcall', {'id': roll_call_id}))\n",
    "        return data['roll_call']\n",
    "\n",
    "legis = LegiScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4883ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Running this cell will create one API call to the getDatasetList endpoint,\n",
    "plus one call to the getDataset endpoint for each dataset with an updated change hash. \"\"\"\n",
    "\n",
    "datasets = legis.get_dataset_list(state = 'me')\n",
    "\n",
    "stored_hashes_loc = 'lkesich.legiscan_stored_hashes'\n",
    "stored_hashes = rs.query(f'select * from {stored_hashes_loc}')\n",
    "hash_dict = dict(zip(stored_hashes['session_id'], stored_hashes['dataset_hash']))\n",
    "\n",
    "session_ids = []\n",
    "dataset_hashes = []\n",
    " \n",
    "votes = []\n",
    "bills = []\n",
    "people = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    session_id = dataset['session_id']\n",
    "    access_key = dataset['access_key']\n",
    "    dataset_hash = dataset['dataset_hash']\n",
    "    \n",
    "    session_ids.append(session_id)\n",
    "    dataset_hashes.append(dataset_hash)\n",
    "    \n",
    "    if hash_dict.get(session_id) == dataset_hash:\n",
    "        continue\n",
    "        \n",
    "    api_output = legis.get_dataset(session_id, access_key)\n",
    "    encoded = base64.b64decode(api_output['zip'])\n",
    "    zipped = zipfile.ZipFile(io.BytesIO(encoded))\n",
    "    files = zipped.namelist()\n",
    "    \n",
    "    for file in files:\n",
    "        content = zipped.read(file).decode(\"utf-8\")\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            if '/bill/' in file:\n",
    "                bills.append(data['bill'])\n",
    "            elif '/vote/' in file:\n",
    "                votes.append(data['roll_call'])\n",
    "            elif '/people/' in file:\n",
    "                data['person']['session_id'] = session_id\n",
    "                people.append(data['person'])       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4be2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_df(df):\n",
    "    \n",
    "    nested_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if isinstance(df[col][0],list):\n",
    "            nested_cols.append(col)\n",
    "            \n",
    "    new_names = []\n",
    "    old_names = df.columns\n",
    "\n",
    "    for old_name in old_names:\n",
    "        new_name = old_name.split('.')[-1]\n",
    "        new_names.append(new_name)\n",
    "            \n",
    "    name_dict = dict(zip(old_names, new_names))\n",
    "    \n",
    "    output = df.rename(columns = name_dict)\n",
    "    \n",
    "    output.drop(columns = nested_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    output.mask(output.applymap(type).eq(list) & ~output.astype(bool), inplace = True)\n",
    "    output.replace({np.nan: None}, inplace = True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def clean_names(tbl, prefix = ''):\n",
    "    old_names = tbl.columns\n",
    "    \n",
    "    for old_name in tbl.columns:\n",
    "        new_name = old_name.replace(prefix,'')\n",
    "        try:\n",
    "            tbl.rename_column(old_name, new_name)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d330bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "redshift INFO Building staging table: lkesich.legiscan_people_stg_20240506_1035_4331\n",
      "redshift INFO lkesich.legiscan_people_stg_20240506_1035_4331 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_people_stg_20240506_1035_4331.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_people\n",
      "redshift INFO lkesich.legiscan_people_stg_20240506_1035_4331 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_people vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1036_3562\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1036_3562 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1036_3562.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1036_3562 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_roll_calls_stg_20240506_1036_2159\n",
      "redshift INFO lkesich.legiscan_roll_calls_stg_20240506_1036_2159 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_roll_calls_stg_20240506_1036_2159.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_roll_calls\n",
      "redshift INFO lkesich.legiscan_roll_calls_stg_20240506_1036_2159 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_roll_calls vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1036_8756\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1036_8756 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1036_8756.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1036_8756 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_bills_stg_20240506_1036_0700\n",
      "redshift INFO lkesich.legiscan_bills_stg_20240506_1036_0700 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_bills_stg_20240506_1036_0700.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_bills\n",
      "redshift INFO lkesich.legiscan_bills_stg_20240506_1036_0700 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_bills vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1037_6834\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1037_6834 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1037_6834.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1037_6834 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_votes_stg_20240506_1037_2286\n",
      "redshift INFO lkesich.legiscan_votes_stg_20240506_1037_2286 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_votes_stg_20240506_1037_2286.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_votes\n",
      "redshift INFO lkesich.legiscan_votes_stg_20240506_1037_2286 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_votes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1037_4237\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1037_4237 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1037_4237.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1037_4237 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_subjects_stg_20240506_1037_0602\n",
      "redshift INFO lkesich.legiscan_subjects_stg_20240506_1037_0602 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_subjects_stg_20240506_1037_0602.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_subjects\n",
      "redshift INFO lkesich.legiscan_subjects_stg_20240506_1037_0602 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_subjects vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1038_8019\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1038_8019 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1038_8019.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1038_8019 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_sponsors_stg_20240506_1038_6573\n",
      "redshift INFO lkesich.legiscan_sponsors_stg_20240506_1038_6573 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_sponsors_stg_20240506_1038_6573.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_sponsors\n",
      "redshift INFO lkesich.legiscan_sponsors_stg_20240506_1038_6573 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_sponsors vacuumed.\n",
      "redshift INFO Building staging table: lkesich.legiscan_stored_hashes_stg_20240506_1039_5083\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1039_5083 created.\n",
      "rs_copy_table INFO Data type is csv\n",
      "redshift INFO Data copied to lkesich.legiscan_stored_hashes_stg_20240506_1039_5083.\n",
      "redshift INFO Target rows inserted to lkesich.legiscan_stored_hashes\n",
      "redshift INFO lkesich.legiscan_stored_hashes_stg_20240506_1039_5083 staging table dropped.\n",
      "redshift INFO lkesich.legiscan_stored_hashes vacuumed.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Check if new data is available \"\"\"\n",
    "new_hashes = table.from_columns([session_ids,dataset_hashes], header = ['session_id','dataset_hash'])\n",
    "\n",
    "check_hashes = stored_hashes\n",
    "check_hashes.stack(new_hashes)\n",
    "check_hashes.deduplicate()\n",
    "\n",
    "if check_hashes.num_rows == new_hashes.num_rows:\n",
    "    print(\"Legiscan data is already up to date\")\n",
    "else:\n",
    "    \"\"\" Unpack nested columns into separate tables + clean column names \"\"\"            \n",
    "    bill_df = pd.json_normalize(bills)\n",
    "    vote_df = pd.json_normalize(votes)\n",
    "    people_df = pd.json_normalize(people)\n",
    "\n",
    "    # roll call\n",
    "    roll_call_tbl = table.from_dataframe(bill_df).long_table('bill_id','votes')\n",
    "    roll_call_tbl.rename_column('votes_roll_call_id','roll_call_id')\n",
    "\n",
    "    # subjects\n",
    "    subjects_tbl = table.from_dataframe(bill_df).long_table('bill_id','subjects')\n",
    "    clean_names(subjects_tbl, 'subjects_')\n",
    "\n",
    "    # sponsors\n",
    "    sponsors_tbl = table.from_dataframe(bill_df).long_table('bill_id','sponsors')\n",
    "    clean_names(sponsors_tbl, 'sponsors_')\n",
    "\n",
    "    # vote\n",
    "    vote_tbl = table.from_dataframe(vote_df).long_table(['roll_call_id','bill_id'],'votes')\n",
    "    clean_names(vote_tbl, 'votes_')\n",
    "\n",
    "    # bill\n",
    "    simplified_bill_df = simplify_df(bill_df)\n",
    "    bill_tbl = table.from_dataframe(simplified_bill_df)\n",
    "    bill_tbl.rename_column('name','committee_name')\n",
    "\n",
    "    # person\n",
    "    people_df['party_id'] = pd.to_numeric(people_df['party_id'])\n",
    "    simplified_people_df = simplify_df(people_df)\n",
    "\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 8855, 'name'] = 'Michel Lajoie'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 8855, 'first_name'] = 'Michel'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 21232, 'name'] = 'Tiffany Roberts'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 21232, 'last_name'] = 'Roberts'\n",
    "\n",
    "    people_tbl = table.from_dataframe(simplified_people_df)\n",
    "    \n",
    "    legiscan_tables = [\n",
    "        {\n",
    "            'table':'legiscan_people',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': ['people_id','session_id'],\n",
    "            'sortkey': 'people_id',\n",
    "            'distkey': 'people_id',\n",
    "            'tbl': people_tbl\n",
    "        },\n",
    "        {\n",
    "            'table':'legiscan_roll_calls',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': 'roll_call_id',\n",
    "            'sortkey': 'votes_date',\n",
    "            'distkey': 'roll_call_id',\n",
    "            'tbl': roll_call_tbl\n",
    "        },\n",
    "        {\n",
    "            'table':'legiscan_bills',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': 'bill_id',\n",
    "            'sortkey': 'session_id',\n",
    "            'distkey': 'bill_id',\n",
    "            'tbl': bill_tbl\n",
    "        },\n",
    "        {\n",
    "            'table':'legiscan_votes',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': ['roll_call_id','people_id'],\n",
    "            'sortkey': 'roll_call_id, people_id',\n",
    "            'distkey': 'roll_call_id',\n",
    "            'tbl': vote_tbl\n",
    "        },\n",
    "        {\n",
    "            'table':'legiscan_subjects',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': ['bill_id','subject_id'],\n",
    "            'sortkey': 'subject_id',\n",
    "            'distkey': 'bill_id',\n",
    "            'tbl': subjects_tbl\n",
    "        },\n",
    "        {\n",
    "            'table':'legiscan_sponsors',\n",
    "            'schema': 'lkesich',\n",
    "            'primarykey': ['people_id','bill_id'],\n",
    "            'sortkey': 'people_id',\n",
    "            'distkey': 'bill_id',\n",
    "            'tbl': sponsors_tbl\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \"\"\" Update or create all data tables in redshift. \"\"\"\n",
    "    for key in legiscan_tables:\n",
    "        tbl = key['tbl']\n",
    "        target_table = key['schema'] + '.' + key['table']\n",
    "        distkey = key['distkey']\n",
    "        sortkey = key['sortkey']\n",
    "        primary_key = key['primarykey']\n",
    "\n",
    "        if rs.table_exists(target_table):\n",
    "            rs.upsert(\n",
    "                tbl,\n",
    "                target_table,\n",
    "                primary_key,\n",
    "                distkey,\n",
    "                sortkey\n",
    "            )\n",
    "        else:\n",
    "            rs.copy(\n",
    "                tbl,\n",
    "                target_table,\n",
    "                if_exists = \"drop\",\n",
    "                distkey = distkey,\n",
    "                sortkey = sortkey\n",
    "            )\n",
    "            \n",
    "        \n",
    "    \"\"\" Update stored dataset hashes in redshift. \"\"\"\n",
    "    rs.upsert(new_hashes, stored_hashes_loc, 'session_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legiscan",
   "language": "python",
   "name": "legiscan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
