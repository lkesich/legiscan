{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42908a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parsons import Table, GoogleBigQuery\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import zipfile\n",
    "import io\n",
    "from urllib.parse import urlencode, quote_plus\n",
    "\n",
    "table = Table()\n",
    "bq = GoogleBigQuery()\n",
    "\n",
    "# bigquery\n",
    "bq_project = 'av-states'\n",
    "bq_dataset = 'lkesich'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d579c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### pylegiscan functions adapted from https://github.com/poliquin/pylegiscan/blob/master/pylegiscan/legiscan.py\n",
    "\n",
    "class LegiScanError(Exception):\n",
    "    pass\n",
    "\n",
    "class LegiScan(object):\n",
    "    BASE_URL = 'http://api.legiscan.com/?key={0}&op={1}&{2}'\n",
    "\n",
    "    def __init__(self, apikey=None):\n",
    "        \"\"\"LegiScan API.  State parameters should always be passed as\n",
    "           USPS abbreviations.  Bill numbers and abbreviations are case\n",
    "           insensitive.  Register for API at http://legiscan.com/legiscan\n",
    "        \"\"\"\n",
    "        # see if API key available as environment variable\n",
    "        if apikey is None:\n",
    "            apikey = os.getenv('LEGISCAN_API_KEY')\n",
    "        self.key = apikey.strip()\n",
    "\n",
    "    def _url(self, operation, params=None):\n",
    "        \"\"\"Build a URL for querying the API.\"\"\"\n",
    "        if not isinstance(params, str) and params is not None:\n",
    "            params = urlencode(params)\n",
    "        elif params is None:\n",
    "            params = ''\n",
    "        return self.BASE_URL.format(self.key, operation, params)\n",
    "\n",
    "    def _get(self, url):\n",
    "        \"\"\"Get and parse JSON from API for a url.\"\"\"\n",
    "        req = requests.get(url)\n",
    "        if not req.ok:\n",
    "            raise LegiScanError('Request returned {0}: {1}'\\\n",
    "                    .format(req.status_code, url))\n",
    "        data = json.loads(req.content)\n",
    "        if data['status'] == \"ERROR\":\n",
    "            raise LegiScanError(data['alert']['message'])\n",
    "        return data\n",
    "\n",
    "    def get_session_list(self, state):\n",
    "        \"\"\"Get list of available sessions for a state.\"\"\"\n",
    "        url = self._url('getSessionList', {'state': state})\n",
    "        data = self._get(url)\n",
    "        return data['sessions']\n",
    "\n",
    "    def get_dataset_list(self, state=None, year=None):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getDatasetList', {'state': state})\n",
    "        elif year is not None:\n",
    "            url = self._url('getDatasetList', {'year': year})\n",
    "        else:\n",
    "            url = self._url('getDatasetList')\n",
    "        data = self._get(url)\n",
    "        return data['datasetlist']\n",
    "\n",
    "    def get_dataset(self, id, access_key):\n",
    "        \"\"\"Get list of available datasets, with optional state and year filtering.\n",
    "        \"\"\"\n",
    "        url = self._url('getDataset', {'id': id, 'access_key': access_key})\n",
    "        data = self._get(url)\n",
    "        return data['dataset']\n",
    "    \n",
    "    def get_session_people(self, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier.\n",
    "        \"\"\"\n",
    "        if session_id is not None:\n",
    "            url = self._url('getSessionPeople', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier.')\n",
    "        data = self._get(url)\n",
    "        return data['sessionpeople']\n",
    "      \n",
    "    def get_master_list(self, state=None, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getMasterList', {'state': state})\n",
    "        elif session_id is not None:\n",
    "            url = self._url('getMasterList', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier or state.')\n",
    "        data = self._get(url)\n",
    "        return [data['masterlist'][i] for i in data['masterlist']]\n",
    "    \n",
    "    def get_master_list_raw(self, state=None, session_id=None):\n",
    "        \"\"\"Get list of bills for the current session in a state or for\n",
    "           a given session identifier, optimized for change hash detection.\n",
    "        \"\"\"\n",
    "        if state is not None:\n",
    "            url = self._url('getMasterListRaw', {'state': state})\n",
    "        elif session_id is not None:\n",
    "            url = self._url('getMasterListRaw', {'id': session_id})\n",
    "        else:\n",
    "            raise ValueError('Must specify session identifier or state.')\n",
    "        data = self._get(url)\n",
    "        return [data['masterlist'][i] for i in data['masterlist']]\n",
    "\n",
    "    def get_bill(self, bill_id=None, state=None, bill_number=None):\n",
    "        \"\"\"Get primary bill detail information including sponsors, committee\n",
    "           references, full history, bill text, and roll call information.\n",
    "\n",
    "           This function expects either a bill identifier or a state and bill\n",
    "           number combination.  The bill identifier is preferred, and required\n",
    "           for fetching bills from prior sessions.\n",
    "        \"\"\"\n",
    "        if bill_id is not None:\n",
    "            url = self._url('getBill', {'id': bill_id})\n",
    "        elif state is not None and bill_number is not None:\n",
    "            url = self._url('getBill', {'state': state, 'bill': bill_number})\n",
    "        else:\n",
    "            raise ValueError('Must specify bill_id or state and bill_number.')\n",
    "        return self._get(url)['bill']\n",
    "\n",
    "    def get_roll_call(self, roll_call_id):\n",
    "        \"\"\"Roll call detail for individual votes and summary information.\"\"\"\n",
    "        data = self._get(self._url('getRollcall', {'id': roll_call_id}))\n",
    "        return data['roll_call']\n",
    "\n",
    "legis = LegiScan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4883ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Running this cell will create one API call to the getDatasetList endpoint,\n",
    "plus one call to the getDataset endpoint for each dataset with an updated change hash. \"\"\"\n",
    "\n",
    "datasets = legis.get_dataset_list(state = 'me')\n",
    "\n",
    "stored_hashes_loc = f'{bq_project}.{bq_dataset}.legiscan_stored_hashes'\n",
    "stored_hashes = bq.query(f'select * from {stored_hashes_loc}')\n",
    "hash_dict = dict(zip(stored_hashes['session_id'], stored_hashes['dataset_hash']))\n",
    "\n",
    "session_ids = []\n",
    "dataset_hashes = []\n",
    " \n",
    "votes = []\n",
    "bills = []\n",
    "people = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    session_id = dataset['session_id']\n",
    "    access_key = dataset['access_key']\n",
    "    dataset_hash = dataset['dataset_hash']\n",
    "    \n",
    "    session_ids.append(session_id)\n",
    "    dataset_hashes.append(dataset_hash)\n",
    "    \n",
    "    if hash_dict.get(session_id) == dataset_hash:\n",
    "        continue\n",
    "        \n",
    "    api_output = legis.get_dataset(session_id, access_key)\n",
    "    encoded = base64.b64decode(api_output['zip'])\n",
    "    zipped = zipfile.ZipFile(io.BytesIO(encoded))\n",
    "    files = zipped.namelist()\n",
    "    \n",
    "    for file in files:\n",
    "        content = zipped.read(file).decode(\"utf-8\")\n",
    "        try:\n",
    "            data = json.loads(content)\n",
    "            if '/bill/' in file:\n",
    "                bills.append(data['bill'])\n",
    "            elif '/vote/' in file:\n",
    "                votes.append(data['roll_call'])\n",
    "            elif '/people/' in file:\n",
    "                data['person']['session_id'] = session_id\n",
    "                people.append(data['person'])       \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4be2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_df(df):\n",
    "    \n",
    "    nested_cols = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if any(isinstance(item,list) for item in df[col]):\n",
    "            nested_cols.append(col)\n",
    "            \n",
    "    old_names = df.columns\n",
    "    new_names = [name.replace('.','_') for name in old_names]       \n",
    "    name_dict = {k:v for (k,v) in zip(old_names, new_names) if k!=v}\n",
    "\n",
    "    # rename columns\n",
    "    output = df.rename(columns = name_dict)\n",
    "\n",
    "    # replace nulls\n",
    "    output.replace({np.nan: None}, inplace = True)\n",
    "\n",
    "    # drop nested columns\n",
    "    output.drop(columns = nested_cols, axis = 1, inplace = True)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def clean_table(tbl, prefix = ''):\n",
    "    \n",
    "    # rename columns\n",
    "    old_cols = tbl.columns\n",
    "    new_cols = [c.replace('.','_').replace(prefix,'') for c in old_cols]\n",
    "\n",
    "    name_dict = {k:v for (k,v) in (zip(old_cols,new_cols)) if k!=v}\n",
    "    tbl.rename_columns(name_dict)\n",
    "\n",
    "    for col in new_cols:\n",
    "\n",
    "        # convert all ids to numeric\n",
    "        if col[-3:] == '_id':\n",
    "            tbl.convert_column(col,int)\n",
    "        \n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4525e0b2-f765-43f1-95a3-72f2baf411d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class='petl'>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>session_id</th>\n",
       "<th>dataset_hash</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td style='text-align: right'>48</td>\n",
       "<td>20c496d1e0212856d370536e382b9691</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='text-align: right'>81</td>\n",
       "<td>82da33fa25759d5eaca5c3ad267571ce</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='text-align: right'>1004</td>\n",
       "<td>7d47cf9e6077e5265ec38de8d7a9cea3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='text-align: right'>1132</td>\n",
       "<td>9b146a7c1144ab48d291b0081f49a7a4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td style='text-align: right'>1258</td>\n",
       "<td>88e0805a4e5ecdae319bb8a24f8137ae</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "<p><strong>...</strong></p>"
      ],
      "text/plain": [
       "{'session_id': 48, 'dataset_hash': '20c496d1e0212856d370536e382b9691'}\n",
       "{'session_id': 81, 'dataset_hash': '82da33fa25759d5eaca5c3ad267571ce'}\n",
       "{'session_id': 1004, 'dataset_hash': '7d47cf9e6077e5265ec38de8d7a9cea3'}\n",
       "{'session_id': 1132, 'dataset_hash': '9b146a7c1144ab48d291b0081f49a7a4'}\n",
       "{'session_id': 1258, 'dataset_hash': '88e0805a4e5ecdae319bb8a24f8137ae'}\n",
       "..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Check if new data is available \"\"\"\n",
    "new_hashes = table.from_columns([session_ids,dataset_hashes], header = ['session_id','dataset_hash'])\n",
    "\n",
    "check_hashes = stored_hashes\n",
    "check_hashes.stack(new_hashes)\n",
    "check_hashes.deduplicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d330bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_people_stg_20240722_1113_0182\n",
      "google_cloud_storage INFO 283824f3-61b9-402a-a88d-448c87761d57.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_people_stg_20240722_1113_0182\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_roll_calls_stg_20240722_1113_9774\n",
      "google_cloud_storage INFO 46e26876-af9c-4d48-9824-f1b8ba248775.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_roll_calls_stg_20240722_1113_9774\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_bills_stg_20240722_1113_0412\n",
      "google_cloud_storage INFO b0cde665-4ad3-40aa-9235-7743f51d80d2.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_bills_stg_20240722_1113_0412\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_votes_stg_20240722_1113_5993\n",
      "google_cloud_storage INFO 76b81269-4ae5-4939-a131-69a803447ebb.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_votes_stg_20240722_1113_5993\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_subjects_stg_20240722_1114_2973\n",
      "google_cloud_storage INFO 9a464b59-4239-4202-8e4f-39db6b5a07e1.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_subjects_stg_20240722_1114_2973\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_sponsors_stg_20240722_1114_4429\n",
      "google_cloud_storage INFO 9f67b2ac-ed6c-48f6-b5bc-156e6f926f0d.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_sponsors_stg_20240722_1114_4429\n",
      "google_bigquery INFO Building staging table: av-states.lkesich.legiscan_stored_hashes_stg_20240722_1114_1347\n",
      "google_cloud_storage INFO c71a66eb-37b8-4027-a5f2-8d0d78ef1ad3.csv blob in lydia-scratch bucket deleted.\n",
      "google_bigquery INFO Deleting staging table: av-states.lkesich.legiscan_stored_hashes_stg_20240722_1114_1347\n"
     ]
    }
   ],
   "source": [
    "if check_hashes.num_rows == new_hashes.num_rows:\n",
    "    print(\"Legiscan data is already up to date\")\n",
    "else:\n",
    "    \"\"\" Unpack nested columns into separate tables + clean column names \"\"\"            \n",
    "    bill_df = pd.json_normalize(bills)\n",
    "    vote_df = pd.json_normalize(votes)\n",
    "    people_df = pd.json_normalize(people)\n",
    "\n",
    "    # roll call\n",
    "    roll_call_tbl = table.from_dataframe(bill_df).long_table('bill_id','votes')\n",
    "    roll_call_tbl.rename_column('votes_roll_call_id','roll_call_id')\n",
    "    clean_table(roll_call_tbl)\n",
    "\n",
    "    # subjects\n",
    "    subjects_tbl = table.from_dataframe(bill_df).long_table('bill_id','subjects')\n",
    "    clean_table(subjects_tbl, 'subjects_')\n",
    "\n",
    "    # sponsors\n",
    "    sponsors_tbl = table.from_dataframe(bill_df).long_table('bill_id','sponsors')\n",
    "    clean_table(sponsors_tbl, 'sponsors_')\n",
    "\n",
    "    # vote\n",
    "    vote_tbl = table.from_dataframe(vote_df).long_table(['roll_call_id','bill_id'],'votes')\n",
    "    clean_table(vote_tbl, 'votes_')\n",
    "\n",
    "    # bill\n",
    "    simplified_bill_df = simplify_df(bill_df)\n",
    "    bill_tbl = table.from_dataframe(simplified_bill_df)\n",
    "    clean_table(bill_tbl)\n",
    "\n",
    "    # person\n",
    "    #people_df['party_id'] = pd.to_numeric(people_df['party_id'])\n",
    "    simplified_people_df = simplify_df(people_df)\n",
    "\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 8855, 'name'] = 'Michel Lajoie'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 8855, 'first_name'] = 'Michel'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 21232, 'name'] = 'Tiffany Roberts'\n",
    "    simplified_people_df.loc[simplified_people_df['people_id'] == 21232, 'last_name'] = 'Roberts'\n",
    "\n",
    "    people_tbl = table.from_dataframe(simplified_people_df)\n",
    "    clean_table(people_tbl)\n",
    "    \n",
    "    legiscan_tables = [\n",
    "        {\n",
    "            'name':'legiscan_people',\n",
    "            'primarykey': ['people_id','session_id'],\n",
    "            'data': people_tbl\n",
    "        },\n",
    "        {\n",
    "            'name':'legiscan_roll_calls',\n",
    "            'primarykey': 'roll_call_id',\n",
    "            'data': roll_call_tbl\n",
    "        },\n",
    "        {\n",
    "            'name':'legiscan_bills',\n",
    "            'primarykey': 'bill_id',\n",
    "            'data': bill_tbl\n",
    "        },\n",
    "        {\n",
    "            'name':'legiscan_votes',\n",
    "            'primarykey': ['roll_call_id','people_id'],\n",
    "            'data': vote_tbl\n",
    "        },\n",
    "        {\n",
    "            'name':'legiscan_subjects',\n",
    "            'primarykey': ['bill_id','subject_id'],\n",
    "            'data': subjects_tbl\n",
    "        },\n",
    "        {\n",
    "            'name':'legiscan_sponsors',\n",
    "            'primarykey': ['people_id','bill_id'],\n",
    "            'data': sponsors_tbl\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "\n",
    "    \"\"\" Update or create all data tables in BigQuery. \"\"\"\n",
    "    for t in legiscan_tables:\n",
    "        table_obj = t['data']\n",
    "        target_table = f'''{bq_project}.{bq_dataset}.{t['name']}'''\n",
    "        primary_key = t['primarykey']\n",
    "\n",
    "        bq.upsert(table_obj, target_table, primary_key)\n",
    "        \n",
    "    \"\"\" Update stored dataset hashes in redshift. \"\"\"\n",
    "    bq.upsert(new_hashes, stored_hashes_loc, 'session_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "legiscan",
   "language": "python",
   "name": "legiscan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
